{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Performance Input Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spec = {\n",
    "    'state': tf.io.FixedLenFeature([21,21,2], tf.float32),\n",
    "    'distr': tf.io.FixedLenFeature([21,21,1], tf.float32)\n",
    "}\n",
    "schema = dataset_schema.from_feature_spec(feature_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfr_input_fn(filename_pattern, batch_size, options):\n",
    "    \n",
    "    def _input_fn():\n",
    "        dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "            file_pattern=filename_pattern,\n",
    "            batch_size=batch_size,\n",
    "            features=feature_spec,\n",
    "            shuffle_buffer_size=options['shuffle_buffer_size'],\n",
    "            prefetch_buffer_size=options['prefetch_buffer_size'],\n",
    "            reader_num_threads=options['reader_num_threads'],\n",
    "            parser_num_threads=options['parser_num_threads'],\n",
    "            sloppy_ordering=options['sloppy_ordering'],\n",
    "            num_epochs=options['num_epochs'],\n",
    "            label_key='distr')\n",
    "\n",
    "        if options['distribute']:\n",
    "            return dataset \n",
    "        else:\n",
    "            return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern='deleteme.tfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_tfr_input_fn(\n",
    "    filename_pattern=file_pattern,\n",
    "    batch_size=5, \n",
    "    options={'num_epochs': None,  # repeat infinitely\n",
    "             'shuffle_buffer_size': 40,\n",
    "             'prefetch_buffer_size': 40,\n",
    "             'reader_num_threads': 10,\n",
    "             'parser_num_threads': 10,\n",
    "             'sloppy_ordering': True,\n",
    "             'distribute': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This design pattern allows us to provide parameters to a function that is not allowed to take some. We essentially have a function now that provides its parameters to a *daughter* function as constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we will provide this ```train_input_fn``` to the so-called ```estimator```. It is then up to the ```estimator``` to call ```train_input_fn``` and by that create the input-generating computational sub-graph within it's own graph and session context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we call the function ourselves and see what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': <tf.Tensor 'IteratorGetNext_2:0' shape=(5, 21, 21, 2) dtype=float32>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_2:1' shape=(5, 21, 21, 1) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each time we evaluate ```samples``` and ```labels```, we'll get a new batch of 1000 samples with the associated 'humidity' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    s, l = sess.run([samples, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 21, 21, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
